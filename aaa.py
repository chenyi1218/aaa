# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import google.generativeai as genai
import io

# --- Streamlit é é¢è¨­å®š (å¿…é ˆæ˜¯ç¬¬ä¸€å€‹ Streamlit å‘½ä»¤) ---
st.set_page_config(page_title="å¿ƒç†å¥åº·è³‡æ–™åˆ†æ + AI å•ç­”", layout="wide")

# --- è¨­å®š Gemini æ¨¡å‹åç¨± ---
TARGET_GEMINI_MODEL = "models/gemini-1.5-flash"

# ====================================================================================
# ä½¿ç”¨ @st.cache_resource ä¾†å¿«å– Gemini æ¨¡å‹ç‰©ä»¶çš„è¼‰å…¥
@st.cache_resource
def get_gemini_model_cached(target_model_name, api_key):
    """
    å¿«å– Gemini æ¨¡å‹ç‰©ä»¶çš„åˆå§‹åŒ–ã€‚
    åªæœ‰åœ¨ç¬¬ä¸€æ¬¡èª¿ç”¨æ™‚æœƒåŸ·è¡Œ genai.GenerativeModel()ã€‚
    """
    if not api_key:
        return None
    try:
        genai.configure(api_key=api_key)
        _ = list(genai.list_models())
        model_instance = genai.GenerativeModel(target_model_name)
        return model_instance
    except Exception as e:
        return None

# ====================================================================================

# --- é é¢æ¨™é¡Œèˆ‡åœ–ç‰‡ ---
st.image("https://cdn-icons-png.flaticon.com/512/2331/2331970.png", width=80)
st.title("ğŸ§  å¿ƒç†å¥åº·è³‡æ–™åˆ†æå¹³å°")
st.markdown("æœ¬å¹³å°æ”¯æ´ä¸Šå‚³ CSV æª”é€²è¡Œè¦–è¦ºåŒ–åˆ†æï¼Œä¸¦å¯ä½¿ç”¨ Gemini AI é€²è¡Œå•ç­”äº’å‹•ã€‚")

# --- åŠŸèƒ½åˆ‡æ›ï¼šé é¢é ‚éƒ¨çš„ Tabs ---
tab_csv_upload, tab_gemini_ai = st.tabs(["ğŸ“ ä¸Šå‚³ CSV", "ğŸ¤– Gemini AI å•ç­”"])

# --- åŠŸèƒ½ä¸€ï¼šCSV ä¸Šå‚³èˆ‡åˆ†æ (åœ¨ç¬¬ä¸€å€‹ Tab ä¸­) ---
with tab_csv_upload:
    st.subheader("ğŸ“Š è³‡æ–™åˆ†æèˆ‡è¦–è¦ºåŒ–")
    uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ CSV æª”æ¡ˆ", type="csv", key="csv_uploader_main")

    if uploaded_file:
        with st.spinner("â³ æ­£åœ¨è®€å–ä¸¦åˆ†ææ‚¨çš„ CSV æª”æ¡ˆ..."):
            try:
                @st.cache_data
                def load_csv_data(file):
                    return pd.read_csv(file)

                df = load_csv_data(uploaded_file)
                st.session_state.uploaded_df = df
                st.success("âœ… ä¸Šå‚³æˆåŠŸï¼ä»¥ä¸‹ç‚ºè³‡æ–™å…§å®¹é è¦½ï¼š")
                st.dataframe(df.head())

                st.markdown("### ğŸ“ è³‡æ–™æ¦‚è¦½")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("è³‡æ–™ç­†æ•¸", len(df))
                with col2:
                    st.metric("æ¬„ä½æ•¸", len(df.columns))
                with col3:
                    st.metric("ç¼ºå€¼ç¸½æ•¸", df.isnull().sum().sum())

                with st.expander("ğŸ“ˆ é»æ“ŠæŸ¥çœ‹æ•¸å€¼æ¬„ä½è¦–è¦ºåŒ–"):
                    numeric_cols = df.select_dtypes(include='number').columns
                    if len(numeric_cols) > 0:
                        selected_col = st.selectbox("é¸æ“‡è¦åˆ†æçš„æ•¸å€¼æ¬„ä½", numeric_cols, key="numeric_col_select")
                        chart_type = st.radio(
                            "é¸æ“‡åœ–è¡¨é¡å‹",
                            ["ç›´æ–¹åœ– (åˆ†ä½ˆ)", "ç®±å½¢åœ– (åˆ†ä½ˆèˆ‡ç•°å¸¸å€¼)"],
                            horizontal=True,
                            key="chart_type_radio"
                        )
                        fig, ax = plt.subplots()
                        if chart_type == "ç›´æ–¹åœ– (åˆ†ä½ˆ)":
                            ax.set_title(f'{selected_col} åˆ†ä½ˆ')
                            ax.set_xlabel(selected_col)
                            ax.set_ylabel('é »ç‡')
                            df[selected_col].hist(ax=ax, bins=20, edgecolor='black')
                            st.pyplot(fig)
                        elif chart_type == "ç®±å½¢åœ– (åˆ†ä½ˆèˆ‡ç•°å¸¸å€¼)":
                            ax.set_title(f'{selected_col} ç®±å½¢åœ–')
                            ax.set_ylabel(selected_col)
                            df.boxplot(column=selected_col, ax=ax)
                            st.pyplot(fig)
                    else:
                        st.warning("æ­¤è³‡æ–™é›†ç„¡å¯è¦–è¦ºåŒ–çš„æ•¸å€¼æ¬„ä½ã€‚")

                with st.expander("ğŸ“Š é»æ“ŠæŸ¥çœ‹é¡åˆ¥æ¬„ä½åˆ†ä½ˆ"):
                    categorical_cols = df.select_dtypes(include='object').columns
                    if len(categorical_cols) > 0:
                        selected_cat_col = st.selectbox("é¸æ“‡è¦åˆ†æçš„é¡åˆ¥æ¬„ä½", categorical_cols, key="cat_col_select")
                        st.write(f"**{selected_cat_col} çš„è¨ˆæ•¸åˆ†ä½ˆï¼š**")
                        st.bar_chart(df[selected_cat_col].value_counts())
                    else:
                        st.info("æ­¤è³‡æ–™é›†ç„¡é¡åˆ¥æ¬„ä½å¯ä¾›åˆ†æã€‚")

            except Exception as e:
                st.error(f"âŒ è®€å– CSV æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                st.info("è«‹ç¢ºèªæ‚¨ä¸Šå‚³çš„æ˜¯æœ‰æ•ˆçš„ CSV æª”æ¡ˆï¼Œä¸¦ä¸”ç·¨ç¢¼æ­£ç¢ºã€‚")
                if 'uploaded_df' in st.session_state:
                    del st.session_state.uploaded_df
    else:
        st.info("è«‹ä¸Šå‚³ä¸€å€‹ CSV æª”æ¡ˆä¾†é–‹å§‹åˆ†æã€‚")
        if 'uploaded_df' in st.session_state:
            del st.session_state.uploaded_df

# --- åŠŸèƒ½äºŒï¼šGemini AI å•ç­” (åœ¨ç¬¬äºŒå€‹ Tab ä¸­) ---
with tab_gemini_ai:
    st.subheader("ğŸ¤– AI å•ç­”åŠ©ç†ï¼ˆGeminiï¼‰")

    # --- ç”¨æˆ¶è¼¸å…¥ API é‡‘é‘° ---
    st.markdown("#### ğŸ”‘ è¼¸å…¥æ‚¨çš„ Gemini API é‡‘é‘°")
    if "gemini_api_key_input" not in st.session_state:
        st.session_state.gemini_api_key_input = ""

    current_api_key = st.text_input(
        "è«‹åœ¨æ­¤è™•è¼¸å…¥æ‚¨çš„ Gemini API é‡‘é‘°ï¼š",
        type="password",
        value=st.session_state.gemini_api_key_input,
        key="gemini_api_key_text_input",
        help="å‰å¾€ Google AI Studio (aistudio.google.com/app/apikey) ç²å–æ‚¨çš„é‡‘é‘°ã€‚"
    )

    if current_api_key and current_api_key != st.session_state.gemini_api_key_input:
        st.session_state.gemini_api_key_input = current_api_key
        st.rerun()

    model = get_gemini_model_cached(TARGET_GEMINI_MODEL, current_api_key)

    if model:
        st.sidebar.success(f"âœ… Gemini æ¨¡å‹ '{TARGET_GEMINI_MODEL}' å·²æˆåŠŸè¼‰å…¥ã€‚")
        gemini_api_working = True
    else:
        st.sidebar.error(f"âŒ ç„¡æ³•è¼‰å…¥ Gemini æ¨¡å‹ '{TARGET_GEMINI_MODEL}'ã€‚")
        if not current_api_key:
            st.sidebar.warning("è«‹åœ¨ AI å•ç­”å€åŸŸè¼¸å…¥æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚")
        else:
            st.sidebar.info("è«‹æª¢æŸ¥æ‚¨çš„ API é‡‘é‘°æ˜¯å¦æœ‰æ•ˆã€ç¶²è·¯é€£ç·šï¼Œæˆ–å˜—è©¦åˆ·æ–°é é¢ã€‚")
        gemini_api_working = False

    if gemini_api_working and "messages" in st.session_state and st.session_state.messages:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è¨˜éŒ„", help="é»æ“Šæ­¤æŒ‰éˆ•å°‡åˆªé™¤æ‰€æœ‰èŠå¤©å°è©±è¨˜éŒ„", key="clear_chat_button"):
            st.session_state.messages = []
            if "chat" in st.session_state:
                del st.session_state.chat
            st.rerun()

    # --- æª¢æŸ¥ API é‡‘é‘°æŒ‰éˆ• ---
    if st.button("ğŸ” æª¢æŸ¥ API é‡‘é‘°", key="check_api_button"):
        with st.spinner("æ­£åœ¨æª¢æŸ¥é‡‘é‘°..."):
            try:
                genai.configure(api_key=current_api_key)
                _ = genai.list_models()
                st.success("âœ… æ‚¨çš„ API é‡‘é‘°æœ‰æ•ˆï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
            except Exception as e:
                st.error(f"âŒ æ‚¨çš„ API é‡‘é‘°ç„¡æ•ˆæˆ–ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                st.warning("è«‹ç¢ºèªæ‚¨è¼¸å…¥çš„é‡‘é‘°æ­£ç¢ºï¼Œæˆ–å˜—è©¦é‡æ–°ç”Ÿæˆä¸€å€‹ã€‚")
    
    # --- è‡ªå‹•ç”Ÿæˆå ±å‘ŠæŒ‰éˆ• ---
    if gemini_api_working and 'uploaded_df' in st.session_state and not st.session_state.uploaded_df.empty:
        if st.button("âœï¸ è‡ªå‹•ç”Ÿæˆæ•¸æ“šå ±å‘Š", help="é»æ“Šæ­¤æŒ‰éˆ•è®“ AI æ ¹æ“šç•¶å‰æ•¸æ“šç”Ÿæˆä¸€ä»½å ±å‘Š", key="generate_report_button"):
            with st.spinner("AI æ­£åœ¨åˆ†ææ•¸æ“šä¸¦ç”Ÿæˆå ±å‘Š..."):
                try:
                    df_to_analyze = st.session_state.uploaded_df

                    # å‰µå»ºæ›´ç²¾ç°¡çš„æ•¸æ“šä¸Šä¸‹æ–‡
                    data_summary_text = f"""
                    è³‡æ–™é›†åŒ…å« {df_to_analyze.shape[0]} è¡Œå’Œ {df_to_analyze.shape[1]} åˆ—ã€‚
                    æ¬„ä½åç¨±å’Œè³‡æ–™é¡å‹ï¼š\n{df_to_analyze.dtypes.to_string()}
                    æ•¸å€¼æ¬„ä½çš„çµ±è¨ˆæ‘˜è¦ï¼š\n{df_to_analyze.describe().to_string()}
                    """

                    # å‰µå»ºè‡ªå‹•ç”Ÿæˆå ±å‘Šçš„å°ˆç”¨æç¤ºè©
                    report_prompt = f"""
                    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ•¸æ“šåˆ†æå¸«ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šä»¥ä¸‹æä¾›çš„æ•¸æ“šæ‘˜è¦ï¼Œç”Ÿæˆä¸€ä»½å°ˆæ¥­ä¸”çµæ§‹åŒ–çš„åˆ†æå ±å‘Šã€‚

                    å ±å‘Šå¿…é ˆåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
                    ### 1. æ•¸æ“šæ¦‚è¦½
                    - ç°¡è¦æè¿°æ•¸æ“šé›†çš„è¦æ¨¡ï¼ˆè¡Œã€åˆ—æ•¸ï¼‰ã€‚
                    - ç°¡è¦æè¿°å„å€‹æ¬„ä½çš„è³‡æ–™é¡å‹å’Œç¼ºå€¼æƒ…æ³ã€‚

                    ### 2. é—œéµç™¼ç¾
                    - æ‰¾å‡ºæ•¸æ“šä¸­çš„ä¸»è¦è¶¨å‹¢ã€æ¨¡å¼æˆ–é—œä¿‚ã€‚
                    - åˆ†ææ•¸å€¼æ¬„ä½çš„çµ±è¨ˆæ‘˜è¦ï¼Œä¾‹å¦‚å¹³å‡æ•¸ã€ä¸­ä½æ•¸ã€æœ€å¤§å€¼ã€æœ€å°å€¼ç­‰ã€‚
                    - åˆ†æé¡åˆ¥æ¬„ä½çš„åˆ†ä½ˆæƒ…æ³ï¼Œä¾‹å¦‚å„å€‹é¡åˆ¥çš„æ•¸é‡ã€‚

                    ### 3. æ½›åœ¨æ´å¯Ÿèˆ‡å»ºè­°
                    - æ ¹æ“šä½ çš„ç™¼ç¾ï¼Œæå‡ºæœ‰åƒ¹å€¼çš„æ´å¯Ÿã€‚
                    - é‡å°æ•¸æ“šä¸­çš„å•é¡Œï¼ˆä¾‹å¦‚ï¼šç¼ºå€¼ï¼‰ï¼Œæä¾›ä¸‹ä¸€æ­¥çš„è™•ç†å»ºè­°ã€‚
                    
                    ---
                    ä»¥ä¸‹æ˜¯æ‚¨éœ€è¦åˆ†æçš„ CSV è³‡æ–™çš„ä¸Šä¸‹æ–‡ï¼š

                    {data_summary_text}
                    """
                    
                    response = model.generate_content(report_prompt)
                    report_text = response.text
                    st.session_state.messages.append({"role": "model", "parts": report_text})
                    st.rerun()  # æ–°å¢é€™ä¸€è¡Œä¾†æ›´æ–°èŠå¤©æ¡†é¡¯ç¤º

                except Exception as e:
                    st.error(f"âŒ ç”Ÿæˆå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                    st.info("è«‹æª¢æŸ¥æ‚¨çš„ API é‡‘é‘°è¨­å®šï¼Œæˆ–åˆ·æ–°é é¢å¾Œé‡è©¦ã€‚")
    
    if not gemini_api_working:
        st.warning("âš ï¸ Gemini AI åŠ©ç†ç›®å‰ç„¡æ³•ä½¿ç”¨ï¼Œå› ç‚º API é‡‘é‘°ç„¡æ•ˆæˆ–æ¨¡å‹æœªæ­£ç¢ºè¼‰å…¥ã€‚")
        st.info("è«‹è¼¸å…¥æ‚¨çš„ Gemini API é‡‘é‘°ä¸¦å˜—è©¦åˆ·æ–°é é¢ã€‚")
    else:
        if "messages" not in st.session_state:
            st.session_state.messages = []

        if "chat" not in st.session_state or st.session_state.chat is None:
            try:
                st.session_state.chat = model.start_chat(history=st.session_state.messages)
            except Exception as e:
                st.error(f"âŒ ç„¡æ³•å•Ÿå‹• Gemini èŠå¤©æœƒè©±ï¼š{e}")
                st.info("é€™å¯èƒ½æ˜¯ç”±æ–¼ API é‡‘é‘°å•é¡Œæˆ–æ¨¡å‹ç„¡æ³•åˆå§‹åŒ–ã€‚")
                st.session_state.chat = None

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["parts"])
        
        uploaded_df_exists = 'uploaded_df' in st.session_state and st.session_state.uploaded_df is not None and not st.session_state.uploaded_df.empty
        
        if uploaded_df_exists:
            st.info("æ‚¨å·²ä¸Šå‚³ CSV æª”æ¡ˆã€‚æ‚¨å¯ä»¥å‘ AI åŠ©ç†æå•é—œæ–¼æ­¤è³‡æ–™çš„å•é¡Œï¼")
            st.markdown(f"**ç•¶å‰è³‡æ–™é›†ï¼š** {uploaded_file.name} ({st.session_state.uploaded_df.shape[0]} è¡Œ, {st.session_state.uploaded_df.shape[1]} åˆ—)")
        else:
            st.info("æ‚¨å¯ä»¥å‘ AI åŠ©ç†æå•ä»»ä½•å•é¡Œï¼(è‹¥è¦æå•è³‡æ–™å…§å®¹ï¼Œè«‹å…ˆä¸Šå‚³ CSV æª”æ¡ˆ)")

        user_input = st.chat_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œï¼š", key="gemini_query_input")
        
        if user_input:
            st.session_state.messages.append({"role": "user", "parts": user_input})
            with st.chat_message("user"):
                st.markdown(user_input)
            
            if st.session_state.chat:
                with st.spinner("Gemini æ€è€ƒä¸­... è«‹ç¨å€™ç‰‡åˆ»"):
                    try:
                        full_prompt = user_input
                        if uploaded_df_exists:
                            df_to_analyze = st.session_state.uploaded_df
                            buffer = io.StringIO()
                            df_to_analyze.info(buf=buffer)
                            df_info_str = buffer.getvalue()
                            df_desc_str = df_to_analyze.describe().to_markdown()
                            
                            system_prompt = f"""
                            ä½ æ˜¯ä¸€ä½é ‚å°–çš„æ•¸æ“šåˆ†æå¸«å’Œå¿ƒç†å¥åº·é ˜åŸŸçš„å°ˆå®¶ã€‚
                            ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šæˆ‘æä¾›çš„ CSV æ•¸æ“šå’Œå•é¡Œï¼Œé€²è¡Œå°ˆæ¥­ã€åš´è¬¹çš„åˆ†æï¼Œä¸¦çµ¦å‡ºæœ‰åƒ¹å€¼çš„æ´å¯Ÿèˆ‡å»ºè­°ã€‚
                            ä½ çš„å›è¦†å¿…é ˆçµæ§‹æ¸…æ™°ï¼Œå…ˆåˆ—å‡ºä½ å°‡å¦‚ä½•åˆ†æçš„æ­¥é©Ÿï¼Œå†çµ¦å‡ºçµè«–ã€‚
                            è«‹ä¸è¦æ†‘ç©ºæé€ æ•¸æ“šï¼Œæ‰€æœ‰çµè«–éƒ½å¿…é ˆåš´æ ¼åŸºæ–¼æä¾›çš„æ•¸æ“šã€‚
                            """
                            data_context = f"""
                            ä»¥ä¸‹æ˜¯æ‚¨éœ€è¦åˆ†æçš„ CSV è³‡æ–™çš„ä¸Šä¸‹æ–‡ã€‚
                            è³‡æ–™æ¦‚è¦½ (df.info()):
                            ```
                            {df_info_str}
                            ```
                            è³‡æ–™çµ±è¨ˆæ‘˜è¦ (df.describe()):
                            ```
                            {df_desc_str}
                            ```
                            è³‡æ–™å‰5è¡Œ (df.head()):
                            ```
                            {df_to_analyze.head().to_markdown(index=False)}
                            ```
                            æˆ‘çš„å•é¡Œæ˜¯ï¼š{user_input}
                            """
                            full_prompt = system_prompt + data_context
                            st.markdown("---")
                            st.info("AI æ­£åœ¨åˆ†ææ‚¨ä¸Šå‚³çš„è³‡æ–™ä¸¦é€²è¡Œæ·±åº¦æ€è€ƒ...")
                        
                        response = st.session_state.chat.send_message(full_prompt)
                        ai_response_text = response.text
                        st.session_state.messages.append({"role": "model", "parts": ai_response_text})
                        
                        with st.chat_message("model"):
                            st.markdown(ai_response_text)
                    
                    except Exception as e:
                        st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼Œç„¡æ³•èˆ‡ Gemini é€²è¡Œé€šè¨Šï¼š{e}")
                        st.warning("é€™å¯èƒ½æ˜¯å› ç‚º API é‡‘é‘°ç„¡æ•ˆã€ç¶²è·¯å•é¡Œæˆ–è«‹æ±‚å…§å®¹ä¸ç¬¦åˆæ”¿ç­–ã€‚")
                        st.info("è«‹æª¢æŸ¥æ‚¨çš„ API é‡‘é‘°è¨­å®šï¼Œä¸¦ç¢ºä¿æ‚¨çš„å•é¡Œç¬¦åˆ Google çš„ä½¿ç”¨è¦ç¯„ã€‚")
            else:
                st.error("âŒ èŠå¤©æœƒè©±æœªæˆåŠŸåˆå§‹åŒ–ï¼Œç„¡æ³•ç™¼é€è¨Šæ¯ã€‚")
                st.info("è«‹åœ¨ä¸Šæ–¹è¼¸å…¥æ‚¨çš„ API é‡‘é‘°ï¼Œä¸¦ç¢ºèªæ¨¡å‹ç‹€æ…‹ã€‚")